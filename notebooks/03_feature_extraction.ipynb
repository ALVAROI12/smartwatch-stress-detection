{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb29354",
   "metadata": {},
   "source": [
    "# Step 2.3: Feature Extraction\n",
    "## Windowed Feature Extraction from E4 Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfb196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from scipy import stats, signal\n",
    "from scipy.fft import fft\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_PATH = Path('/home/alvaro-ibarra/smartwatch-stress-detection')\n",
    "WESAD_PATH = BASE_PATH / 'WESAD'\n",
    "EPM_PATH = BASE_PATH / 'EPM-E4' / 'empatica_wearable_data' / 'raw'\n",
    "PHYSIONET_PATH = BASE_PATH / 'wearable-device-dataset' / 'wearable-device-dataset-from-induced-stress-and-structured-exercise-sessions-1.0.1' / 'Wearable_Dataset'\n",
    "OUTPUT_PATH = BASE_PATH / 'data' / 'processed' / 'windowed_features'\n",
    "\n",
    "# Window parameters\n",
    "WINDOW_SIZE_SEC = 60  # 60 seconds\n",
    "OVERLAP = 0.5  # 50% overlap\n",
    "\n",
    "# Sampling rates\n",
    "SR_BVP = 64\n",
    "SR_EDA = 4\n",
    "SR_TEMP = 4\n",
    "SR_ACC = 32\n",
    "SR_HR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3954609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_e4_signal(filepath):\n",
    "    \"\"\"Load E4 CSV signal file.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        timestamp = lines[0].strip().split(',')[0]\n",
    "        sr = float(lines[1].strip().split(',')[0])\n",
    "        data = pd.read_csv(filepath, skiprows=2, header=None)\n",
    "        return data.values, sr, timestamp\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def get_windows(data, sr, window_sec, overlap):\n",
    "    \"\"\"Generate sliding windows.\"\"\"\n",
    "    window_samples = int(window_sec * sr)\n",
    "    step = int(window_samples * (1 - overlap))\n",
    "    windows = []\n",
    "    for start in range(0, len(data) - window_samples + 1, step):\n",
    "        windows.append(data[start:start + window_samples])\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db92a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BVP/HR Feature Extraction\n",
    "def extract_bvp_features(bvp_window, hr_window=None):\n",
    "    \"\"\"Extract BVP and HR features.\"\"\"\n",
    "    features = {}\n",
    "    bvp = bvp_window.flatten()\n",
    "    \n",
    "    # BVP statistics\n",
    "    features['bvp_mean'] = np.mean(bvp)\n",
    "    features['bvp_std'] = np.std(bvp)\n",
    "    features['bvp_min'] = np.min(bvp)\n",
    "    features['bvp_max'] = np.max(bvp)\n",
    "    features['bvp_range'] = features['bvp_max'] - features['bvp_min']\n",
    "    \n",
    "    # Peak detection for HRV\n",
    "    peaks, _ = signal.find_peaks(bvp, distance=int(SR_BVP * 0.5))\n",
    "    if len(peaks) > 1:\n",
    "        ibi = np.diff(peaks) / SR_BVP * 1000  # IBI in ms\n",
    "        features['hr_mean'] = 60000 / np.mean(ibi) if np.mean(ibi) > 0 else np.nan\n",
    "        features['hr_std'] = np.std(60000 / ibi) if len(ibi) > 1 else 0\n",
    "        features['hrv_rmssd'] = np.sqrt(np.mean(np.diff(ibi)**2)) if len(ibi) > 1 else 0\n",
    "        features['hrv_sdnn'] = np.std(ibi) if len(ibi) > 1 else 0\n",
    "        nn_diff = np.abs(np.diff(ibi))\n",
    "        features['hrv_pnn50'] = np.sum(nn_diff > 50) / len(nn_diff) * 100 if len(nn_diff) > 0 else 0\n",
    "    else:\n",
    "        features['hr_mean'] = np.nan\n",
    "        features['hr_std'] = 0\n",
    "        features['hrv_rmssd'] = 0\n",
    "        features['hrv_sdnn'] = 0\n",
    "        features['hrv_pnn50'] = 0\n",
    "    \n",
    "    # Frequency domain (LF/HF ratio)\n",
    "    try:\n",
    "        freqs, psd = signal.welch(bvp, fs=SR_BVP, nperseg=min(256, len(bvp)))\n",
    "        lf_mask = (freqs >= 0.04) & (freqs < 0.15)\n",
    "        hf_mask = (freqs >= 0.15) & (freqs < 0.4)\n",
    "        lf_power = np.trapezoid(psd[lf_mask], freqs[lf_mask]) if np.sum(lf_mask) > 1 else 0\n",
    "        hf_power = np.trapezoid(psd[hf_mask], freqs[hf_mask]) if np.sum(hf_mask) > 1 else 0\n",
    "        features['hrv_lf_hf_ratio'] = lf_power / hf_power if hf_power > 0 else np.nan\n",
    "    except:\n",
    "        features['hrv_lf_hf_ratio'] = np.nan\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5edcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA Feature Extraction\n",
    "def extract_eda_features(eda_window):\n",
    "    \"\"\"Extract EDA features.\"\"\"\n",
    "    features = {}\n",
    "    eda = eda_window.flatten()\n",
    "    \n",
    "    # Basic statistics\n",
    "    features['eda_mean'] = np.mean(eda)\n",
    "    features['eda_std'] = np.std(eda)\n",
    "    features['eda_min'] = np.min(eda)\n",
    "    features['eda_max'] = np.max(eda)\n",
    "    features['eda_range'] = features['eda_max'] - features['eda_min']\n",
    "    \n",
    "    # SCR detection (simple peak detection)\n",
    "    eda_diff = np.diff(eda)\n",
    "    threshold = np.std(eda_diff) * 0.5\n",
    "    peaks, properties = signal.find_peaks(eda, prominence=threshold, distance=int(SR_EDA * 1))\n",
    "    \n",
    "    features['eda_scr_count'] = len(peaks)\n",
    "    if len(peaks) > 0 and 'prominences' in properties:\n",
    "        features['eda_scr_amp_mean'] = np.mean(properties['prominences'])\n",
    "    else:\n",
    "        features['eda_scr_amp_mean'] = 0\n",
    "    \n",
    "    # Tonic/Phasic approximation (simple low-pass for tonic)\n",
    "    try:\n",
    "        b, a = signal.butter(2, 0.05, btype='low', fs=SR_EDA)\n",
    "        tonic = signal.filtfilt(b, a, eda)\n",
    "        phasic = eda - tonic\n",
    "        features['eda_tonic_mean'] = np.mean(tonic)\n",
    "        features['eda_phasic_mean'] = np.mean(np.abs(phasic))\n",
    "    except:\n",
    "        features['eda_tonic_mean'] = features['eda_mean']\n",
    "        features['eda_phasic_mean'] = 0\n",
    "    \n",
    "    # Slope\n",
    "    features['eda_slope'] = (eda[-1] - eda[0]) / len(eda) * SR_EDA\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "127d473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Feature Extraction\n",
    "def extract_temp_features(temp_window):\n",
    "    \"\"\"Extract temperature features.\"\"\"\n",
    "    features = {}\n",
    "    temp = temp_window.flatten()\n",
    "    \n",
    "    features['temp_mean'] = np.mean(temp)\n",
    "    features['temp_std'] = np.std(temp)\n",
    "    features['temp_min'] = np.min(temp)\n",
    "    features['temp_max'] = np.max(temp)\n",
    "    features['temp_range'] = features['temp_max'] - features['temp_min']\n",
    "    features['temp_slope'] = (temp[-1] - temp[0]) / len(temp) * SR_TEMP\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa3befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accelerometer Feature Extraction\n",
    "def extract_acc_features(acc_window):\n",
    "    \"\"\"Extract accelerometer features.\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    if acc_window.shape[1] >= 3:\n",
    "        x, y, z = acc_window[:, 0], acc_window[:, 1], acc_window[:, 2]\n",
    "    else:\n",
    "        x = y = z = acc_window.flatten()\n",
    "    \n",
    "    # Magnitude\n",
    "    magnitude = np.sqrt(x**2 + y**2 + z**2)\n",
    "    \n",
    "    features['acc_mag_mean'] = np.mean(magnitude)\n",
    "    features['acc_mag_std'] = np.std(magnitude)\n",
    "    features['acc_mag_min'] = np.min(magnitude)\n",
    "    features['acc_mag_max'] = np.max(magnitude)\n",
    "    \n",
    "    # Per-axis\n",
    "    features['acc_x_mean'] = np.mean(x)\n",
    "    features['acc_y_mean'] = np.mean(y)\n",
    "    features['acc_z_mean'] = np.mean(z)\n",
    "    features['acc_x_std'] = np.std(x)\n",
    "    features['acc_y_std'] = np.std(y)\n",
    "    features['acc_z_std'] = np.std(z)\n",
    "    \n",
    "    # Signal Magnitude Area\n",
    "    features['acc_sma'] = np.mean(np.abs(x) + np.abs(y) + np.abs(z))\n",
    "    \n",
    "    # Energy\n",
    "    features['acc_energy'] = np.sum(magnitude**2) / len(magnitude)\n",
    "    \n",
    "    # Entropy\n",
    "    hist, _ = np.histogram(magnitude, bins=10, density=True)\n",
    "    hist = hist[hist > 0]\n",
    "    features['acc_entropy'] = -np.sum(hist * np.log2(hist)) if len(hist) > 0 else 0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7682b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(bvp, eda, temp, acc, window_idx):\n",
    "    \"\"\"Extract all features for a window.\"\"\"\n",
    "    features = {'window_id': window_idx}\n",
    "    features.update(extract_bvp_features(bvp))\n",
    "    features.update(extract_eda_features(eda))\n",
    "    features.update(extract_temp_features(temp))\n",
    "    features.update(extract_acc_features(acc))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93382d",
   "metadata": {},
   "source": [
    "## WESAD Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0bd50b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 15 WESAD subjects...\n"
     ]
    }
   ],
   "source": [
    "# WESAD label mapping\n",
    "WESAD_LABELS = {1: 'Baseline', 2: 'Stress', 3: 'Amusement'}\n",
    "\n",
    "wesad_subjects = sorted([d for d in os.listdir(WESAD_PATH) if d.startswith('S') and os.path.isdir(WESAD_PATH / d)], key=lambda x: int(x[1:]))\n",
    "print(f\"Processing {len(wesad_subjects)} WESAD subjects...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4580dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing S2... 89 windows\n",
      "  Processing S3... 81 windows\n",
      "  Processing S4... 86 windows\n",
      "  Processing S5... 86 windows\n",
      "  Processing S6... 82 windows\n",
      "  Processing S7... 87 windows\n",
      "  Processing S8... 86 windows\n",
      "  Processing S9... 84 windows\n",
      "  Processing S10... 91 windows\n",
      "  Processing S11... 87 windows\n",
      "  Processing S13... 87 windows\n",
      "  Processing S14... 90 windows\n",
      "  Processing S15... 90 windows\n",
      "  Processing S16... 90 windows\n",
      "  Processing S17... 89 windows\n",
      "\n",
      "Total WESAD windows: 1305\n",
      "label\n",
      "Baseline     707\n",
      "Stress       389\n",
      "Amusement    209\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "wesad_features = []\n",
    "\n",
    "for subj in wesad_subjects:\n",
    "    print(f\"  Processing {subj}...\", end=' ')\n",
    "    \n",
    "    # Load signals\n",
    "    e4_path = WESAD_PATH / subj / f'{subj}_E4_Data'\n",
    "    bvp_data, _, _ = load_e4_signal(e4_path / 'BVP.csv')\n",
    "    eda_data, _, _ = load_e4_signal(e4_path / 'EDA.csv')\n",
    "    temp_data, _, _ = load_e4_signal(e4_path / 'TEMP.csv')\n",
    "    acc_data, _, _ = load_e4_signal(e4_path / 'ACC.csv')\n",
    "    \n",
    "    # Load labels from pkl\n",
    "    with open(WESAD_PATH / subj / f'{subj}.pkl', 'rb') as f:\n",
    "        pkl_data = pickle.load(f, encoding='latin1')\n",
    "    labels = pkl_data['label']\n",
    "    \n",
    "    # Resample labels to match E4 BVP rate (labels are at 700Hz chest)\n",
    "    label_ratio = len(labels) / len(bvp_data)\n",
    "    \n",
    "    # Create windows\n",
    "    n_windows = int((len(bvp_data) - WINDOW_SIZE_SEC * SR_BVP) / (WINDOW_SIZE_SEC * SR_BVP * (1 - OVERLAP))) + 1\n",
    "    \n",
    "    window_count = 0\n",
    "    for w in range(n_windows):\n",
    "        # Calculate indices for each signal\n",
    "        bvp_start = int(w * WINDOW_SIZE_SEC * SR_BVP * (1 - OVERLAP))\n",
    "        bvp_end = bvp_start + int(WINDOW_SIZE_SEC * SR_BVP)\n",
    "        \n",
    "        eda_start = int(w * WINDOW_SIZE_SEC * SR_EDA * (1 - OVERLAP))\n",
    "        eda_end = eda_start + int(WINDOW_SIZE_SEC * SR_EDA)\n",
    "        \n",
    "        temp_start = int(w * WINDOW_SIZE_SEC * SR_TEMP * (1 - OVERLAP))\n",
    "        temp_end = temp_start + int(WINDOW_SIZE_SEC * SR_TEMP)\n",
    "        \n",
    "        acc_start = int(w * WINDOW_SIZE_SEC * SR_ACC * (1 - OVERLAP))\n",
    "        acc_end = acc_start + int(WINDOW_SIZE_SEC * SR_ACC)\n",
    "        \n",
    "        # Check bounds\n",
    "        if bvp_end > len(bvp_data) or eda_end > len(eda_data) or temp_end > len(temp_data) or acc_end > len(acc_data):\n",
    "            break\n",
    "        \n",
    "        # Get window label (majority vote)\n",
    "        label_start = int(bvp_start * label_ratio)\n",
    "        label_end = int(bvp_end * label_ratio)\n",
    "        window_labels = labels[label_start:label_end]\n",
    "        \n",
    "        # Filter for valid labels (1, 2, 3)\n",
    "        valid_labels = window_labels[(window_labels >= 1) & (window_labels <= 3)]\n",
    "        if len(valid_labels) < len(window_labels) * 0.8:\n",
    "            continue  # Skip windows with too many invalid labels\n",
    "        \n",
    "        majority_label = int(stats.mode(valid_labels, keepdims=False)[0])\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_all_features(\n",
    "            bvp_data[bvp_start:bvp_end],\n",
    "            eda_data[eda_start:eda_end],\n",
    "            temp_data[temp_start:temp_end],\n",
    "            acc_data[acc_start:acc_end],\n",
    "            window_count\n",
    "        )\n",
    "        \n",
    "        features['subject_id'] = subj\n",
    "        features['dataset'] = 'WESAD'\n",
    "        features['label'] = WESAD_LABELS[majority_label]\n",
    "        features['timestamp_start'] = bvp_start / SR_BVP\n",
    "        features['timestamp_end'] = bvp_end / SR_BVP\n",
    "        \n",
    "        wesad_features.append(features)\n",
    "        window_count += 1\n",
    "    \n",
    "    print(f\"{window_count} windows\")\n",
    "\n",
    "wesad_features_df = pd.DataFrame(wesad_features)\n",
    "print(f\"\\nTotal WESAD windows: {len(wesad_features_df)}\")\n",
    "print(wesad_features_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc627ab4",
   "metadata": {},
   "source": [
    "## EPM-E4 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c879040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 47 EPM-E4 subjects...\n"
     ]
    }
   ],
   "source": [
    "# EPM-E4: All data is emotion-elicited (no explicit baseline in E4 files)\n",
    "# Labels come from folder structure and key_moments\n",
    "epm_subjects = sorted([d for d in os.listdir(EPM_PATH) if os.path.isdir(EPM_PATH / d) and d != '.DS_Store'], key=lambda x: int(x))\n",
    "print(f\"Processing {len(epm_subjects)} EPM-E4 subjects...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02564fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGER: 5 key moments\n",
      "FEAR: 9 key moments\n",
      "HAPPINESS: 5 key moments\n",
      "SADNESS: 5 key moments\n"
     ]
    }
   ],
   "source": [
    "# Load key moments for reference\n",
    "key_moments_path = BASE_PATH / 'EPM-E4' / 'key_moments'\n",
    "key_moments = {}\n",
    "for emotion in ['ANGER', 'FEAR', 'HAPPINESS', 'SADNESS']:\n",
    "    km_df = pd.read_csv(key_moments_path / f'{emotion}.csv')\n",
    "    key_moments[emotion] = km_df\n",
    "    print(f\"{emotion}: {len(km_df)} key moments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88a00b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing 1... 49 windows\n",
      "  Processing 2... 46 windows\n",
      "  Processing 4... 52 windows\n",
      "  Processing 12... 60 windows\n",
      "  Processing 14... 47 windows\n",
      "  Processing 15... 49 windows\n",
      "  Processing 16... 47 windows\n",
      "  Processing 24... 54 windows\n",
      "  Processing 25... 62 windows\n",
      "  Processing 34... 52 windows\n",
      "  Processing 35... 66 windows\n",
      "  Processing 36... 47 windows\n",
      "  Processing 39... 62 windows\n",
      "  Processing 40... 49 windows\n",
      "  Processing 45... 51 windows\n",
      "  Processing 47... 55 windows\n",
      "  Processing 49... 49 windows\n",
      "  Processing 55... 50 windows\n",
      "  Processing 56... 50 windows\n",
      "  Processing 61... 49 windows\n",
      "  Processing 66... 49 windows\n",
      "  Processing 68... 51 windows\n",
      "  Processing 72... 68 windows\n",
      "  Processing 76... 55 windows\n",
      "  Processing 77... 53 windows\n",
      "  Processing 78... 70 windows\n",
      "  Processing 79... 53 windows\n",
      "  Processing 81... 45 windows\n",
      "  Processing 86... 50 windows\n",
      "  Processing 91... 52 windows\n",
      "  Processing 92... 52 windows\n",
      "  Processing 103... 50 windows\n",
      "  Processing 106... 72 windows\n",
      "  Processing 107... 59 windows\n",
      "  Processing 117... 48 windows\n",
      "  Processing 121... 52 windows\n",
      "  Processing 122... 48 windows\n",
      "  Processing 124... 49 windows\n",
      "  Processing 126... 62 windows\n",
      "  Processing 128... 55 windows\n",
      "  Processing 129... 65 windows\n",
      "  Processing 131... 56 windows\n",
      "  Processing 137... 48 windows\n",
      "  Processing 138... 53 windows\n",
      "  Processing 141... 49 windows\n",
      "  Processing 159... 47 windows\n",
      "  Processing 160... 53 windows\n",
      "\n",
      "Total EPM-E4 windows: 2510\n"
     ]
    }
   ],
   "source": [
    "epm_features = []\n",
    "\n",
    "for subj in epm_subjects:\n",
    "    print(f\"  Processing {subj}...\", end=' ')\n",
    "    \n",
    "    empatica_path = EPM_PATH / subj / 'empatica'\n",
    "    \n",
    "    # Load signals\n",
    "    bvp_data, _, bvp_ts = load_e4_signal(empatica_path / 'BVP.csv')\n",
    "    eda_data, _, _ = load_e4_signal(empatica_path / 'EDA.csv')\n",
    "    temp_data, _, _ = load_e4_signal(empatica_path / 'TEMP.csv')\n",
    "    acc_data, _, _ = load_e4_signal(empatica_path / 'ACC.csv')\n",
    "    \n",
    "    if bvp_data is None:\n",
    "        print(\"skipped (no data)\")\n",
    "        continue\n",
    "    \n",
    "    # For EPM-E4, label all data as mixed emotional state\n",
    "    # In practice, the entire recording is emotion elicitation\n",
    "    # We'll assign based on the primary emotion being elicited\n",
    "    \n",
    "    # Create windows\n",
    "    n_windows = int((len(bvp_data) - WINDOW_SIZE_SEC * SR_BVP) / (WINDOW_SIZE_SEC * SR_BVP * (1 - OVERLAP))) + 1\n",
    "    \n",
    "    window_count = 0\n",
    "    for w in range(n_windows):\n",
    "        bvp_start = int(w * WINDOW_SIZE_SEC * SR_BVP * (1 - OVERLAP))\n",
    "        bvp_end = bvp_start + int(WINDOW_SIZE_SEC * SR_BVP)\n",
    "        \n",
    "        eda_start = int(w * WINDOW_SIZE_SEC * SR_EDA * (1 - OVERLAP))\n",
    "        eda_end = eda_start + int(WINDOW_SIZE_SEC * SR_EDA)\n",
    "        \n",
    "        temp_start = int(w * WINDOW_SIZE_SEC * SR_TEMP * (1 - OVERLAP))\n",
    "        temp_end = temp_start + int(WINDOW_SIZE_SEC * SR_TEMP)\n",
    "        \n",
    "        acc_start = int(w * WINDOW_SIZE_SEC * SR_ACC * (1 - OVERLAP))\n",
    "        acc_end = acc_start + int(WINDOW_SIZE_SEC * SR_ACC)\n",
    "        \n",
    "        if bvp_end > len(bvp_data) or eda_end > len(eda_data) or temp_end > len(temp_data) or acc_end > len(acc_data):\n",
    "            break\n",
    "        \n",
    "        features = extract_all_features(\n",
    "            bvp_data[bvp_start:bvp_end],\n",
    "            eda_data[eda_start:eda_end],\n",
    "            temp_data[temp_start:temp_end],\n",
    "            acc_data[acc_start:acc_end],\n",
    "            window_count\n",
    "        )\n",
    "        \n",
    "        features['subject_id'] = subj\n",
    "        features['dataset'] = 'EPM-E4'\n",
    "        features['label'] = 'Emotion'  # Will be refined with key_moments\n",
    "        features['timestamp_start'] = bvp_start / SR_BVP\n",
    "        features['timestamp_end'] = bvp_end / SR_BVP\n",
    "        \n",
    "        epm_features.append(features)\n",
    "        window_count += 1\n",
    "    \n",
    "    print(f\"{window_count} windows\")\n",
    "\n",
    "epm_features_df = pd.DataFrame(epm_features)\n",
    "print(f\"\\nTotal EPM-E4 windows: {len(epm_features_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54837fd",
   "metadata": {},
   "source": [
    "## PhysioNet Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cdb66d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded from STRESS: ['f07']\n",
      "Excluded from AEROBIC: ['S12']\n"
     ]
    }
   ],
   "source": [
    "# PhysioNet: Label from protocol folder\n",
    "PHYSIONET_LABELS = {'STRESS': 'Stress', 'AEROBIC': 'Aerobic', 'ANAEROBIC': 'Anaerobic'}\n",
    "\n",
    "# Load exclusion list\n",
    "excluded_df = pd.read_csv(BASE_PATH / 'outputs' / 'tables' / 'excluded_subjects.csv')\n",
    "excluded_stress = excluded_df[(excluded_df['action'] == 'EXCLUDE') & (excluded_df['protocol'] == 'STRESS')]['subject_id'].tolist()\n",
    "excluded_aerobic = excluded_df[(excluded_df['action'] == 'EXCLUDE') & (excluded_df['protocol'] == 'AEROBIC')]['subject_id'].tolist()\n",
    "\n",
    "print(f\"Excluded from STRESS: {excluded_stress}\")\n",
    "print(f\"Excluded from AEROBIC: {excluded_aerobic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628f5518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing STRESS (37 subjects)...\n",
      "  Processing S01... 73 windows\n",
      "  Processing S02... 102 windows\n",
      "  Processing S03... 51 windows\n",
      "  Processing S04... 56 windows\n",
      "  Processing S05... 51 windows\n",
      "  Processing S06... 47 windows\n",
      "  Processing S07... 46 windows\n",
      "  Processing S08... 46 windows\n",
      "  Processing S09... 47 windows\n",
      "  Processing S10... 54 windows\n",
      "  Processing S11... 45 windows\n",
      "  Processing S12... 52 windows\n",
      "  Processing S13... 53 windows\n",
      "  Processing S14... 55 windows\n",
      "  Processing S15... 53 windows\n",
      "  Processing S16... 54 windows\n",
      "  Processing S17... 52 windows\n",
      "  Processing S18... 53 windows\n",
      "  Processing f01... 107 windows\n",
      "  Processing f02... 98 windows\n",
      "  Processing f03... 118 windows\n",
      "  Processing f04... 120 windows\n",
      "  Processing f05... 152 windows\n",
      "  Processing f06... 104 windows\n",
      "  Processing f08... 105 windows\n",
      "  Processing f09... 106 windows\n",
      "  Processing f10... 90 windows\n",
      "  Processing f11... 103 windows\n",
      "  Processing f12... 159 windows\n",
      "  Processing f13... 127 windows\n",
      "  Processing f14_a... 22 windows\n",
      "  Processing f14_b... 71 windows\n",
      "  Processing f15... 139 windows\n",
      "  Processing f16... 106 windows\n",
      "  Processing f17... 113 windows\n",
      "  Processing f18... 103 windows\n",
      "\n",
      "Processing AEROBIC (31 subjects)...\n",
      "  Processing S01... 67 windows\n",
      "  Processing S02... 66 windows\n",
      "  Processing S03... 46 windows\n",
      "  Processing S04... 67 windows\n",
      "  Processing S05... 64 windows\n",
      "  Processing S06... 67 windows\n",
      "  Processing S07... 54 windows\n",
      "  Processing S08... 66 windows\n",
      "  Processing S09... 66 windows\n",
      "  Processing S10... 66 windows\n",
      "  Processing S11_a... 52 windows\n",
      "  Processing S11_b... 8 windows\n",
      "  Processing S13... 68 windows\n",
      "  Processing S14... 71 windows\n",
      "  Processing S15... 66 windows\n",
      "  Processing S16... 67 windows\n",
      "  Processing S17... 66 windows\n",
      "  Processing S18... 67 windows\n",
      "  Processing f01... 88 windows\n",
      "  Processing f02... 57 windows\n",
      "  Processing f03... 88 windows\n",
      "  Processing f04... 82 windows\n",
      "  Processing f05... 101 windows\n",
      "  Processing f06... 89 windows\n",
      "  Processing f07... 76 windows\n",
      "  Processing f08... 78 windows\n",
      "  Processing f09... 85 windows\n",
      "  Processing f10... 85 windows\n",
      "  Processing f11... 62 windows\n",
      "  Processing f12... 73 windows\n",
      "  Processing f13... 85 windows\n",
      "\n",
      "Processing ANAEROBIC (32 subjects)...\n",
      "  Processing S01... 37 windows\n",
      "  Processing S02... 36 windows\n",
      "  Processing S03... 40 windows\n",
      "  Processing S04... 37 windows\n",
      "  Processing S05... 36 windows\n",
      "  Processing S06... 27 windows\n",
      "  Processing S07... 39 windows\n",
      "  Processing S08... 38 windows\n",
      "  Processing S09... 37 windows\n",
      "  Processing S10... 37 windows\n",
      "  Processing S11... 38 windows\n",
      "  Processing S12... 36 windows\n",
      "  Processing S13... 37 windows\n",
      "  Processing S14... 36 windows\n",
      "  Processing S15... 37 windows\n",
      "  Processing S16_a... 18 windows\n",
      "  Processing S16_b... 21 windows\n",
      "  Processing S17... 38 windows\n",
      "  Processing S18... 37 windows\n",
      "  Processing f01... 86 windows\n",
      "  Processing f02... 78 windows\n",
      "  Processing f03... 97 windows\n",
      "  Processing f04... 47 windows\n",
      "  Processing f05... 77 windows\n",
      "  Processing f06... 58 windows\n",
      "  Processing f07... 78 windows\n",
      "  Processing f08... 68 windows\n",
      "  Processing f09... 58 windows\n",
      "  Processing f10... 46 windows\n",
      "  Processing f11... 90 windows\n",
      "  Processing f12... 82 windows\n",
      "  Processing f13... 93 windows\n",
      "\n",
      "Total PhysioNet windows: 6696\n",
      "label\n",
      "Stress       2933\n",
      "Aerobic      2143\n",
      "Anaerobic    1620\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "physionet_features = []\n",
    "\n",
    "for protocol in ['STRESS', 'AEROBIC', 'ANAEROBIC']:\n",
    "    protocol_path = PHYSIONET_PATH / protocol\n",
    "    subjects = sorted([d for d in os.listdir(protocol_path) if os.path.isdir(protocol_path / d)])\n",
    "    \n",
    "    print(f\"\\nProcessing {protocol} ({len(subjects)} subjects)...\")\n",
    "    \n",
    "    for subj in subjects:\n",
    "        # Check exclusion\n",
    "        base_subj = subj.replace('_a', '').replace('_b', '')\n",
    "        if protocol == 'STRESS' and base_subj in excluded_stress:\n",
    "            continue\n",
    "        if protocol == 'AEROBIC' and base_subj in excluded_aerobic:\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Processing {subj}...\", end=' ')\n",
    "        \n",
    "        subj_path = protocol_path / subj\n",
    "        \n",
    "        bvp_data, _, _ = load_e4_signal(subj_path / 'BVP.csv')\n",
    "        eda_data, _, _ = load_e4_signal(subj_path / 'EDA.csv')\n",
    "        temp_data, _, _ = load_e4_signal(subj_path / 'TEMP.csv')\n",
    "        acc_data, _, _ = load_e4_signal(subj_path / 'ACC.csv')\n",
    "        \n",
    "        if bvp_data is None:\n",
    "            print(\"skipped (no data)\")\n",
    "            continue\n",
    "        \n",
    "        n_windows = int((len(bvp_data) - WINDOW_SIZE_SEC * SR_BVP) / (WINDOW_SIZE_SEC * SR_BVP * (1 - OVERLAP))) + 1\n",
    "        \n",
    "        window_count = 0\n",
    "        for w in range(n_windows):\n",
    "            bvp_start = int(w * WINDOW_SIZE_SEC * SR_BVP * (1 - OVERLAP))\n",
    "            bvp_end = bvp_start + int(WINDOW_SIZE_SEC * SR_BVP)\n",
    "            \n",
    "            eda_start = int(w * WINDOW_SIZE_SEC * SR_EDA * (1 - OVERLAP))\n",
    "            eda_end = eda_start + int(WINDOW_SIZE_SEC * SR_EDA)\n",
    "            \n",
    "            temp_start = int(w * WINDOW_SIZE_SEC * SR_TEMP * (1 - OVERLAP))\n",
    "            temp_end = temp_start + int(WINDOW_SIZE_SEC * SR_TEMP)\n",
    "            \n",
    "            acc_start = int(w * WINDOW_SIZE_SEC * SR_ACC * (1 - OVERLAP))\n",
    "            acc_end = acc_start + int(WINDOW_SIZE_SEC * SR_ACC)\n",
    "            \n",
    "            if bvp_end > len(bvp_data) or eda_end > len(eda_data) or temp_end > len(temp_data) or acc_end > len(acc_data):\n",
    "                break\n",
    "            \n",
    "            features = extract_all_features(\n",
    "                bvp_data[bvp_start:bvp_end],\n",
    "                eda_data[eda_start:eda_end],\n",
    "                temp_data[temp_start:temp_end],\n",
    "                acc_data[acc_start:acc_end],\n",
    "                window_count\n",
    "            )\n",
    "            \n",
    "            features['subject_id'] = subj\n",
    "            features['dataset'] = 'PhysioNet'\n",
    "            features['label'] = PHYSIONET_LABELS[protocol]\n",
    "            features['timestamp_start'] = bvp_start / SR_BVP\n",
    "            features['timestamp_end'] = bvp_end / SR_BVP\n",
    "            \n",
    "            physionet_features.append(features)\n",
    "            window_count += 1\n",
    "        \n",
    "        print(f\"{window_count} windows\")\n",
    "\n",
    "physionet_features_df = pd.DataFrame(physionet_features)\n",
    "print(f\"\\nTotal PhysioNet windows: {len(physionet_features_df)}\")\n",
    "print(physionet_features_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff81a4",
   "metadata": {},
   "source": [
    "## Save Windowed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2493e008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  WESAD_windowed_features.csv: 1305 rows\n",
      "  EPM4_windowed_features.csv: 2510 rows\n",
      "  PhysioNet_windowed_features.csv: 6696 rows\n"
     ]
    }
   ],
   "source": [
    "# Save individual dataset features\n",
    "wesad_features_df.to_csv(OUTPUT_PATH / 'WESAD_windowed_features.csv', index=False)\n",
    "epm_features_df.to_csv(OUTPUT_PATH / 'EPM4_windowed_features.csv', index=False)\n",
    "physionet_features_df.to_csv(OUTPUT_PATH / 'PhysioNet_windowed_features.csv', index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\"  WESAD_windowed_features.csv: {len(wesad_features_df)} rows\")\n",
    "print(f\"  EPM4_windowed_features.csv: {len(epm_features_df)} rows\")\n",
    "print(f\"  PhysioNet_windowed_features.csv: {len(physionet_features_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216cdaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2.3 COMPLETE: Feature Extraction\n",
      "============================================================\n",
      "\n",
      "Window size: 60s, Overlap: 50%\n",
      "\n",
      "Features extracted: 40\n",
      "\n",
      "Total windows:\n",
      "  WESAD: 1305\n",
      "  EPM-E4: 2510\n",
      "  PhysioNet: 6696\n",
      "  TOTAL: 10511\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 2.3 COMPLETE: Feature Extraction\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nWindow size: {WINDOW_SIZE_SEC}s, Overlap: {int(OVERLAP*100)}%\")\n",
    "print(f\"\\nFeatures extracted: {len([c for c in wesad_features_df.columns if c not in ['subject_id', 'dataset', 'label', 'window_id', 'timestamp_start', 'timestamp_end']])}\")\n",
    "print(f\"\\nTotal windows:\")\n",
    "print(f\"  WESAD: {len(wesad_features_df)}\")\n",
    "print(f\"  EPM-E4: {len(epm_features_df)}\")\n",
    "print(f\"  PhysioNet: {len(physionet_features_df)}\")\n",
    "print(f\"  TOTAL: {len(wesad_features_df) + len(epm_features_df) + len(physionet_features_df)}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
